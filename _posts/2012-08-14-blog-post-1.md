---
title: 'NSGA-II. Elitist Non-Dominated Sorting Getenic Algorithm'
date: 2024-04-27
permalink: /posts/2024/04/nsga2/
tags:
  - Multi-Objective
  - Optimization
  - Computer Since
---

The main idea of this blog is to explore one of the most popular genetic algorithms for solving MOPs (Multi-Objective Optimization Problems). We define MOPs in a very simple manner, along with the concepts of dominated and non-dominated solutions, to facilitate understanding of the main ideas behind the NSGA-II algorithm.

What is Optimization? and What is multi-objective optimization?
======
When we think about optimization, the word "improvement" often comes to mind. In many cases, this rings true; when we seek to optimize a process, our goal is usually to make it faster or cheaper. However, it ultimately depends on the specific problem and the preferences of the user. These two aspects form the core of the multi-objective problem (MOP). But before delving into that, let's define optimization:

*Optimization is the process of finding the best solution or achieving the most favorable outcome from a set of alternatives, often subject to constraints or limitations.*

In the most fundamental mathematical sense, optimizing a function can be described as follows: Given a function $$f(\textbf{x}) $$, the objective is to determine the value of $$ \textbf{x}$$ at which $$ f $$ is either minimized or maximized.

But what about multi-objective optimization? Well, if we look at our mathematical example, we have one function, which we can call an objective. In multi-objective optimization (MOP), we have multiple functions or objectives to optimize. We can gather these objectives in a vector $$F(\textbf{x}) = [f_{1}(\textbf{x}), f_{2}(\textbf{x}), ... , f_{n}(\textbf{x})]$$, but this raises a lot of questions. What do we want to achieve? Do we want to minimize each $$f_{i}$$ function, or do we want to maximize them? Or perhaps something more complicated, like maximizing $$f_{i}$$ but minimizing $$f_{j}$$. Well, there exist techniques and a theory to address this problem.



How can we address MOPs?
======
To avoid complications, we can try to find all (or as many as we can) of the optimal solutions, and then decide which one is better for us or which is the most adequate to solve our problem, this technique is called "a posteriori technique.". But how do we determine these optimal solutions? To find this out, we need to introduce the concept of dominated and non-dominated solutions.

Imagine we have the solutions $$F_{i} = F(\textbf{x}_{i})$$ for $$i = \{1,2,3,4\}$$, where $$F_{i} \in \mathcal{O}$$ and $$\textbf{x}_{i} \in \mathcal{X}$$. Here, $$\mathcal{O}$$ is the objective space and $$\mathcal{X}$$ is the decision space.

| ![Objective Space](../../../../images/space.png) | 
|:--:| 
| Figure 1: *Objective Space* |

In Figure 1, we observe four solutions. Let's specifically examine $$ F_{2}=F(\textbf{x}_{2}) = [f_{1}(\textbf{x}_{2}),f_{2}(\textbf{x}_{2})] $$. Which solutions are superior to $$F_{2}$$ in terms of minimization?

Our axes represent our objective functions $$ f_{1}(\textbf{x})$$ and $$ f_{2}(\textbf{x}) $$. If we aim to minimize these functions, then the point $$ F_{1}=F(\textbf{x}_{1}) = [f_{1}(\textbf{x}_{1}),f_{2}(\textbf{x}_{1})] $$ is superior to $$F_{2}$$ since $$ f_{1}(\textbf{x}_{1}) < f_{1}(\textbf{x}_{2}) $$ and $$ f_{2}(\textbf{x}_{1}) < f_{2}(\textbf{x}_{2}) $$. Following this logic, we observe that for minimization, the points residing in the third quadrant of a reference system, where the origin is the point in question $$( F_{2} )$$, are superior; these points dominate $$F_{2}$$, such as $$ F_{1} $$ and $$ F_{4} $$. Conversely, the points residing in the second quadrant are dominated by $$ F_{2} $$. The order is reversed in the case of maximization.

We notice that this criterion can't be used to compare $$F_{1}$$ and $$F_{4}$$ since they reside in either the second or third quadrant of their respective reference systems. In this case, we say that these points are indifferent to each other. So, what do we choose? Well, in this scenario, these two solutions are our optimal solutions since they are superior to the other two solutions. These two solutions form what we call a Pareto set, a set of solutions that are superior to the other solutions but cannot be compared between themselves. The points $$\textbf{x} $$ for which we obtain these solutions are our optimal values, denoted by $$\textbf{x}^{*}$$. After identifying this set, we can determine the best solution for our problem.



NSGA-II
======
NSGA-II (Elitist Nondominated Sorting Genetic Algorithm) is a very popular algorithm for solving MOPs. As the name suggests, it is based on maintaining the nondominated solutions in each generation. This sorting process is relatively fast, with a complexity of $$O(MN^{2})$$ (where $$M$$ is the number of objectives and $$N$$ is the population size). In the following subsections, we describe the essential parts of this algorithm.

Fast Nondominated Sorting Approch
-----

The main purpose of this sorting is to assign a rank to each individual (the value in the objective space of each point in the decision space). Individuals with $$rank = 1$$ belong to the first front, those with $$rank = 2$$ belong to the second front, and so on. The best solutions are those residing in the first front, followed by those in the second front, and so forth. The algorithm is presented below, taking as input the population $$P$$ and producing the output as our fronts $$\mathcal{F}_{i}$$.

| ![nondom](../../../../images/nondom.png) | 
|:--:| 
| Figure 2: *Nondominated Sort Algorithm* |

Crowding Distance
-----
Another key factor for the NSGA-II algorithm is the crowding distance. This density estimator helps us maintain diversity in our solutions, meaning that we are interested in a variety of solutions. Therefore, we prioritize points with greater crowding distance.

| ![nondom](../../../../images/crow.png) | 
|:--:| 
| Figure 3: *Crowding Distance* |

The crowding distance associated with the $$i$$ solution is the perimeter of the cuboid formed by the two adjacent solutions $$i + 1$$ and $$i - 1$$. The algorithm is presented below:

| ![nondom](../../../../images/crowal.png) | 
|:--:| 
| Figure 4: *Crowding Distance* |

Here we use Object-Oriented Programming (OOP) notation to indicate that the $$i$$th individual of the front $$\mathcal{F_{j}}$$ possesses the attributes $$\texttt{distance}$$ and $$\texttt{m}$$ (representing the value of the individual in the $$m$$th objective). The parameters $$f_{m}^{max}$$ and $$f_{m}^{min}$$ denote the maximum and minimum values of the $$m$$th objective function.

NSGA-II
-----
With the two key factors mentioned previously, along with the usual binary tournament selection, recombination, and mutation operators, we can implement the NSGA-II algorithm.

| ![nondom](../../../../images/nsga2.png) | 
|:--:| 
| Figure 5: *NSGA-II Algotirhm* |

We can notice that the last front is sorted using the operator $$ \prec_{n} $$. This is because we can't select all the elements of the last front, and we want the best solutions according to the non-dominated sorting and the crowding distance.

The operator $$ \prec_{n} $$ is defined as:

\[ $$i \prec_{n} j$$ \]
if $$(i.rank < j.rank)$$ or $$(i.rank = j.rank) $$ and $$ (i.distance > j.distance) $$

The NSGA-II algorithm is described graphically in the following figure:

| ![nondom](../../../../images/gra.png) | 
|:--:| 
| Figure 6: *NSGA-II Algotirhm Procedure* |

To see the implementation of this algorithm, feel free to check out my [portfolio entry](https://maxgalindo150.github.io/blog/portfolio/).

References
======
[1] Deb, K., Pratap, A., Agarwal, S., & Meyarivan, T. (2002, April). A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II. *IEEE Transactions on Evolutionary Computation*, 6(2).