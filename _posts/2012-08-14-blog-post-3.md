---
title: 'Personal Data Protection in Educational Documents with BERT'
date: 2024-05-30
permalink: /posts/2024/05/pii/
tags:
  - Data Science
  - NLP
  - Computer Sience
---


The protection of personal data in educational documents is a highly relevant topic today, as privacy and the security of personal information are fundamental rights. In this project, an approach based on natural language processing (NLP) and machine learning was implemented for the automated detection of personally identifiable information (PII) in educational documents. By using a pre-trained BERT model and training data annotation in BIO format, a model was trained with remarkable performance in detecting PII in educational texts. The results show an average precision, recall, and F1-score of 0.842, 0.849, and 0.845, respectively, indicating a high capacity for detecting and classifying PII in educational documents. These results suggest that the proposed approach is effective and promising for personal data protection in the educational field, offering an automated and efficient solution to address this challenge.

## Introduction
The protection of personal data in educational documents is a highly relevant topic today, as privacy and the security of personal information are fundamental rights. In Mexico, the General Law on Protection of Personal Data Held by Obligated Subjects (LGPDPPSO) establishes that personal data must be protected and used responsibly. However, in practice, ensuring the privacy of this data in educational documents presents a significant challenge, as these documents contain a large amount of sensitive information susceptible to misuse.

Currently, there are various methods for detecting personal data in educational documents. However, most of these methods are manual and require considerable human effort, which can be inefficient and prone to errors. For this reason, it is crucial to develop automated tools that allow for the detection and protection of personal data in educational documents more efficiently and effectively.

In this project, we used a token classification approach to automate the detection of personal data in educational datasets. This approach is based on advanced techniques of natural language processing (NLP) and machine learning, allowing for the accurate identification and classification of tokens containing personal information. Through the implementation of token classification models, we aim to provide a robust solution to address this challenge.

In the following sections, we will describe the methodology used, present the experiments conducted, and discuss the results obtained, concluding with the implications and possible future directions of this work.

## Background
In the current era, characterized by an abundance of educational data from sources such as educational technology, online learning, and research, the widespread presence of personally identifiable information (PII) represents a key challenge. The presence of PII is a significant barrier to the analysis and creation of open datasets that can drive advancements in education, as the public disclosure of this data can put students at risk. To mitigate these risks, it is crucial to examine and cleanse educational data to remove PII before publication, a task that data science can expedite.

The most reliable method currently for examining data for PII is the manual review of the entire dataset. However, this approach results in significant costs and limits the scalability of educational datasets. While there are automatic techniques for PII detection based on named entity recognition (NER), these work best for PII that shares a common format, such as emails and phone numbers. PII detection systems find it challenging to correctly tag names and distinguish between names that are sensitive (e.g., a student's name) and those that are not (e.g., a cited author's name).

In this context, it is essential to develop more advanced and automated methods for PII detection that can handle the diversity and complexity of educational data. Token classification, a technique in natural language processing (NLP) and machine learning, offers a promising solution to improve the accuracy and efficiency in identifying PII in large datasets. This approach allows for the individual classification and tagging of each token in a text, facilitating precise PII detection at a granular level.

In this project, we focused on implementing a token classification approach based on NER to automate PII detection in educational documents, aiming to overcome the limitations of manual methods and enhance personal data protection in the educational field.

## Methodology
In this project, an approach based on natural language processing (NLP) and machine learning was applied for the automated detection of personally identifiable information (PII) in educational documents. The following steps were taken:

### Data Collection and Preprocessing
A dataset from a Kaggle competition, consisting of approximately 22,000 essays written by students in response to a single assignment prompt, was used. The essays were tokenized using the SpaCy English tokenizer and annotated in BIO format for different types of PII.

A brief data exploration identified the following PII tags: B-EMAIL, B-ID_NUM, B-NAME_STUDENT, B-NAME_TEACHER, B-DATE, B-LOCATION, B-ORGANIZATION, B-URL, B-PHONE, B-ADDRESS, and an O label, as shown in Figure 1.


| ![Number of each tag in the dataset.](../../../../images/labels.png) | 
|:--:| 
| *Figure 1: Number of each tag in the dataset* |


Additionally, to enable the BERT model to process the data, the texts were tokenized and converted into token vectors, then split into training, validation, and test sets.

### Model Training
For PII detection, the pre-trained BERT (Bidirectional Encoder Representations from Transformers) model was employed. BERT is a transformer-based language model that has demonstrated high effectiveness in various NLP tasks, including named entity recognition (NER) for PII detection.

The training configuration is detailed in Table 1.

### Model Evaluation
To evaluate the model's performance, standard metrics such as precision, recall, and F1-score were used on a reserved test dataset. Additionally, cross-validation tests were conducted to ensure the model's generalization capability across different data partitions.

This training and evaluation process was repeated over several epochs to improve the model's performance and ensure its generalization capability. The results obtained are presented in the next section.



| ![Token Classification Model Pipeline](../../../../images/arqui.svg) | 
|:--:| 
| *Figure 2: Token Classification Model Pipeline* |

### Details on the Pre-trained BERT Model
BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based language model developed by Google AI. The key to its effectiveness lies in its ability to capture the bidirectional context of words in a sequence using a transformer architecture.

- Pre-trained Model: For this project, BERT-base-cased was used, which is the base version of BERT trained with English text and is case-sensitive.
- Processing Capacity: BERT can handle sequences of up to 1024 tokens, making it suitable for tasks requiring contextual understanding over long sequences, such as PII detection in extensive texts.
- Fine-tuning: The pre-trained model was fine-tuned using the annotated data from the Kaggle competition, adapting the final layers for the specific task of named entity recognition (NER).
- BERT has proven effective in various NLP applications and has set new standards in natural language processing tasks, including PII detection in educational texts as applied in this project.

| Parameter                         | Value             |
| --------------------------------- | ----------------- |
| Seed                              | 42                |
| Pre-trained Model                 | BERT-base-cased   |
| Training Batch Size               | 4                 |
| Evaluation Batch Size             | 4                 |
| Epochs                            | 3                 |
| Learning Rate                     | 2e-5              |
| Labels                            | B-EMAIL, B-ID_NUM, B-NAME_STUDENT, ... |
| Number of Labels                  | 13                |


If you're interested in learning more about BERT and Transformers, I encourage you to check out my other [blog posts](http://localhost:4000/blog/year-archive/).

## Results
Despite computational power limitations, a model with remarkable performance in detecting PII in educational documents was successfully trained. The results are summarized in Table 2.

| Metric                | Value   |
| --------------------- | ------- |
| Cross-Entropy Loss    | 0.00049 |
| Precision             | 0.842   |
| Recall                | 0.849   |
| F1-score              | 0.845   |

During training, a consistent decrease in the loss function was observed over the epochs, suggesting effective learning by the model. Figure 3 shows the evolution of the loss function during the training process.


| ![Evolution of the Loss Function during Training](../../../../images/loss.png) | 
|:--:| 
| *Figure 3: Evolution of the Loss Function during Training* |


Precision, recall, and F1-score metrics also showed continuous improvement over the epochs, indicating an increase in the model's performance. Figures 4, 5, and 6 illustrate the evolution of these metrics during training.

| ![Evolution of Precision](../../../../images/eval.png) | ![Evolution of F1-score](../../../../images/f1.png) | ![Evolution of Recall](../../../../images/recall.png) |
|:--:|:--:|:--:|
| *Figure 4: Evolution of Precision* | *Figure 5: Evolution of F1-score* | *Figure 6: Evolution of Recall* |

Through these evaluations, it is concluded that the trained model provides an efficient and effective solution for the automated detection of PII in educational documents, meeting the expectations and objectives set for this project.

## Example
To see the model in action, we input the following sentence: *"My name is Frank, and my email is frank@gmail.com."* The model successfully identified the personal information within the sentence.


```python
token_classifier('My name is Frank, and my email is frank@gmail.com.')
```




    [{'entity_group': 'NAME_STUDENT',
      'score': 0.5923071,
      'word': 'Frank',
      'start': 11,
      'end': 16},
     {'entity_group': 'EMAIL',
      'score': 0.62551314,
      'word': 'f',
      'start': 30,
      'end': 31},
     {'entity_group': 'EMAIL',
      'score': 0.74226135,
      'word': 'g',
      'start': 36,
      'end': 37}]



The model correctly identifies the student's name, and email. Although it occasionally misses in some sentences, overall, it performs well in detecting personal information with relatively minor errors. To see how this model was trained and the source code, you can visit my [portfolio entry](http://maxgalindo.sytes.net/portfolio/).

## Conclusions
In this project, an approach based on natural language processing (NLP) and machine learning was implemented for the automated detection of personally identifiable information (PII) in educational documents. By using a pre-trained BERT model and training data annotation in BIO format, a model with remarkable performance in detecting PII in educational texts was trained. The results show an average precision, recall, and F1-score of 0.842, 0.849, and 0.845, respectively, indicating a high capacity for detecting and classifying PII in educational documents. These results suggest that the proposed approach is effective and promising for personal data protection in the educational field, offering an automated and efficient solution to address this challenge. This model can be implemented on English texts, leaving the possibility open to adapt it to other languages.


## References
